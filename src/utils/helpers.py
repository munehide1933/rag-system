# utils/helpers.py
"""
å·¥å…·å‡½æ•°é›†åˆ
åŒ…å«ï¼šé‡è¯•æœºåˆ¶ã€æ—¥å¿—ç³»ç»Ÿã€æ€§èƒ½ç›‘æ§ã€ç¼“å­˜ç­‰
"""
import time
import logging
import sys
import hashlib
import pickle
from pathlib import Path
from functools import wraps
from contextlib import contextmanager
from typing import Callable, Iterator, List, TypeVar, Optional, Any, Dict
from collections import defaultdict

# ============================================
# 1. é‡è¯•æœºåˆ¶
# ============================================

def retry_on_failure(
    max_retries: int = 3,
    delay: float = 1.0,
    backoff: float = 2.0,
    exceptions: tuple = (Exception,),
    logger: logging.Logger = None
):
    """
    é‡è¯•è£…é¥°å™¨
    
    Args:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        delay: åˆå§‹å»¶è¿Ÿï¼ˆç§’ï¼‰
        backoff: å»¶è¿Ÿå€å¢å› å­
        exceptions: éœ€è¦é‡è¯•çš„å¼‚å¸¸ç±»å‹
        logger: æ—¥å¿—è®°å½•å™¨
        
    Example:
        @retry_on_failure(max_retries=3, delay=1.0)
        def fetch_data():
            return requests.get(url)
    """
    def decorator(func: Callable):
        @wraps(func)
        def wrapper(*args, **kwargs):
            current_delay = delay
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    
                    if attempt < max_retries - 1:
                        msg = f"âš ï¸  {func.__name__} å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}"
                        if logger:
                            logger.warning(msg)
                        else:
                            print(msg)
                            
                        time.sleep(current_delay)
                        current_delay *= backoff
                    else:
                        msg = f"âŒ {func.__name__} æœ€ç»ˆå¤±è´¥: {e}"
                        if logger:
                            logger.error(msg)
                        else:
                            print(msg)
                        raise
                        
            raise last_exception
            
        return wrapper
    return decorator


# ============================================
# 2. æ—¥å¿—ç³»ç»Ÿ
# ============================================

class ColoredFormatter(logging.Formatter):
    """å¸¦é¢œè‰²çš„æ—¥å¿—æ ¼å¼åŒ–å™¨ï¼ˆä»…åœ¨ç»ˆç«¯æ˜¾ç¤ºï¼‰"""
    
    COLORS = {
        'DEBUG': '\033[36m',    # é’è‰²
        'INFO': '\033[32m',     # ç»¿è‰²
        'WARNING': '\033[33m',  # é»„è‰²
        'ERROR': '\033[31m',    # çº¢è‰²
        'CRITICAL': '\033[35m', # ç´«è‰²
    }
    RESET = '\033[0m'
    
    def format(self, record):
        # æ·»åŠ é¢œè‰²
        if sys.stdout.isatty():  # åªåœ¨ç»ˆç«¯æ˜¾ç¤ºé¢œè‰²
            levelname = record.levelname
            if levelname in self.COLORS:
                record.levelname = f"{self.COLORS[levelname]}{levelname}{self.RESET}"
                
        return super().format(record)


def setup_logger(
    name: str = "RAG",
    level: str = "INFO",
    log_file: Optional[str] = None,
    console_output: bool = True,
    colored_output: bool = True
) -> logging.Logger:
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿ
    
    Args:
        name: æ—¥å¿—åç§°
        level: æ—¥å¿—çº§åˆ«
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        console_output: æ˜¯å¦è¾“å‡ºåˆ°æ§åˆ¶å°
        colored_output: æ§åˆ¶å°æ˜¯å¦ä½¿ç”¨é¢œè‰²
        
    Returns:
        é…ç½®å¥½çš„ Logger
        
    Example:
        logger = setup_logger("RAG", "INFO", "logs/app.log")
        logger.info("ç³»ç»Ÿå¯åŠ¨")
    """
    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, level.upper()))
    
    # é¿å…é‡å¤æ·»åŠ  handler
    if logger.handlers:
        return logger
    
    # æ ¼å¼åŒ–å™¨
    log_format = '%(asctime)s | %(levelname)-8s | %(name)s | %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    
    # æ§åˆ¶å°è¾“å‡º
    if console_output:
        console_handler = logging.StreamHandler(sys.stdout)
        
        if colored_output:
            console_formatter = ColoredFormatter(log_format, datefmt=date_format)
        else:
            console_formatter = logging.Formatter(log_format, datefmt=date_format)
            
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)
    
    # æ–‡ä»¶è¾“å‡º
    if log_file:
        Path(log_file).parent.mkdir(parents=True, exist_ok=True)
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_formatter = logging.Formatter(log_format, datefmt=date_format)
        file_handler.setFormatter(file_formatter)
        logger.addHandler(file_handler)
    
    return logger


# ============================================
# 3. æ€§èƒ½ç›‘æ§
# ============================================

class PerformanceMetrics:
    """
    æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨
    
    Example:
        metrics = PerformanceMetrics()
        
        with metrics.timer('embedding'):
            embed_documents()
            
        metrics.increment('documents_processed', 10)
        metrics.print_stats()
    """
    
    def __init__(self):
        self.timings: Dict[str, List[float]] = defaultdict(list)
        self.counters: Dict[str, int] = defaultdict(int)
        self.start_time = time.time()
        
    @contextmanager
    def timer(self, name: str):
        """è®¡æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        start = time.time()
        try:
            yield
        finally:
            elapsed = time.time() - start
            self.timings[name].append(elapsed)
            
    def increment(self, name: str, value: int = 1):
        """å¢åŠ è®¡æ•°å™¨"""
        self.counters[name] += value
        
    def set_counter(self, name: str, value: int):
        """è®¾ç½®è®¡æ•°å™¨"""
        self.counters[name] = value
        
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        # è®¡æ—¶ç»Ÿè®¡
        for name, times in self.timings.items():
            if times:
                stats[name] = {
                    'count': len(times),
                    'total': sum(times),
                    'avg': sum(times) / len(times),
                    'min': min(times),
                    'max': max(times)
                }
        
        # è®¡æ•°å™¨
        stats['counters'] = dict(self.counters)
        
        # æ€»è¿è¡Œæ—¶é—´
        stats['total_runtime'] = time.time() - self.start_time
        
        return stats
        
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_stats()
        
        print("\n" + "="*60)
        print("ğŸ“Š æ€§èƒ½ç»Ÿè®¡")
        print("="*60)
        
        # è®¡æ—¶ç»Ÿè®¡
        timing_stats = {k: v for k, v in stats.items() if k not in ['counters', 'total_runtime']}
        if timing_stats:
            print("\nâ±ï¸  è®¡æ—¶:")
            for name, data in timing_stats.items():
                print(f"\n  {name}:")
                print(f"    è°ƒç”¨æ¬¡æ•°: {data['count']}")
                print(f"    æ€»æ—¶é—´: {data['total']:.2f}s")
                print(f"    å¹³å‡: {data['avg']:.3f}s")
                print(f"    èŒƒå›´: {data['min']:.3f}s - {data['max']:.3f}s")
        
        # è®¡æ•°å™¨
        if stats.get('counters'):
            print("\nğŸ”¢ è®¡æ•°å™¨:")
            for name, count in stats['counters'].items():
                print(f"    {name}: {count:,}")
        
        # æ€»è¿è¡Œæ—¶é—´
        print(f"\nâ° æ€»è¿è¡Œæ—¶é—´: {stats['total_runtime']:.2f}s")
        print("="*60 + "\n")
        
    def reset(self):
        """é‡ç½®æ‰€æœ‰ç»Ÿè®¡"""
        self.timings.clear()
        self.counters.clear()
        self.start_time = time.time()


# ============================================
# 4. ç¼“å­˜ç³»ç»Ÿ
# ============================================

class DiskCache:
    """
    ç£ç›˜ç¼“å­˜ç³»ç»Ÿï¼ˆç”¨äºç¼“å­˜ embeddingï¼‰
    
    Example:
        cache = DiskCache("data/cache")
        
        # è·å–ç¼“å­˜
        embedding = cache.get(text)
        if embedding is None:
            embedding = compute_embedding(text)
            cache.set(text, embedding)
    """
    
    def __init__(self, cache_dir: str = "data/cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
    def _get_key(self, text: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®ï¼ˆMD5 å“ˆå¸Œï¼‰"""
        return hashlib.md5(text.encode('utf-8')).hexdigest()
        
    def get(self, text: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        key = self._get_key(text)
        cache_file = self.cache_dir / f"{key}.pkl"
        
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
            except Exception as e:
                print(f"âš ï¸  ç¼“å­˜è¯»å–å¤±è´¥: {e}")
                return None
                
        return None
        
    def set(self, text: str, value: Any):
        """è®¾ç½®ç¼“å­˜"""
        key = self._get_key(text)
        cache_file = self.cache_dir / f"{key}.pkl"
        
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(value, f)
        except Exception as e:
            print(f"âš ï¸  ç¼“å­˜å†™å…¥å¤±è´¥: {e}")
            
    def clear(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        count = 0
        for cache_file in self.cache_dir.glob("*.pkl"):
            cache_file.unlink()
            count += 1
        print(f"âœ… å·²æ¸…é™¤ {count} ä¸ªç¼“å­˜æ–‡ä»¶")
        
    def size(self) -> int:
        """è·å–ç¼“å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        total_size = 0
        for cache_file in self.cache_dir.glob("*.pkl"):
            total_size += cache_file.stat().st_size
        return total_size
        
    def count(self) -> int:
        """è·å–ç¼“å­˜æ–‡ä»¶æ•°é‡"""
        return len(list(self.cache_dir.glob("*.pkl")))
        
    def stats(self):
        """æ‰“å°ç¼“å­˜ç»Ÿè®¡"""
        count = self.count()
        size = self.size()
        size_mb = size / (1024 * 1024)
        
        print(f"ğŸ“¦ ç¼“å­˜ç»Ÿè®¡:")
        print(f"   æ–‡ä»¶æ•°: {count:,}")
        print(f"   æ€»å¤§å°: {size_mb:.2f} MB")


# ============================================
# 5. æ‰¹å¤„ç†å·¥å…·
# ============================================

T = TypeVar('T')

def batch_iterator(
    items: List[T],
    batch_size: int
) -> Iterator[List[T]]:
    """
    æ‰¹é‡è¿­ä»£å™¨
    
    Args:
        items: é¡¹ç›®åˆ—è¡¨
        batch_size: æ‰¹æ¬¡å¤§å°
        
    Yields:
        æ‰¹æ¬¡åˆ—è¡¨
        
    Example:
        for batch in batch_iterator(documents, 32):
            process_batch(batch)
    """
    for i in range(0, len(items), batch_size):
        yield items[i:i + batch_size]


def file_batch_iterator(
    directory: Path,
    file_extensions: List[str],
    batch_size: int = 32,
    recursive: bool = True
) -> Iterator[List[Path]]:
    """
    æ–‡ä»¶æ‰¹å¤„ç†è¿­ä»£å™¨
    
    Args:
        directory: ç›®å½•è·¯å¾„
        file_extensions: æ–‡ä»¶æ‰©å±•ååˆ—è¡¨
        batch_size: æ‰¹æ¬¡å¤§å°
        recursive: æ˜¯å¦é€’å½’æœç´¢
        
    Yields:
        æ–‡ä»¶è·¯å¾„æ‰¹æ¬¡
        
    Example:
        for file_batch in file_batch_iterator(Path("documents/"), ['.pdf', '.txt']):
            process_files(file_batch)
    """
    files = []
    
    for ext in file_extensions:
        if recursive:
            files.extend(directory.rglob(f"*{ext}"))
        else:
            files.extend(directory.glob(f"*{ext}"))
    
    for batch in batch_iterator(files, batch_size):
        yield batch


# ============================================
# 6. è¿›åº¦æ˜¾ç¤º
# ============================================

def show_progress(
    iterable,
    desc: str = "Processing",
    total: int = None,
    unit: str = "it",
    disable: bool = False
):
    """
    æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆåŸºäº tqdmï¼‰
    
    Args:
        iterable: å¯è¿­ä»£å¯¹è±¡
        desc: æè¿°
        total: æ€»æ•°
        unit: å•ä½
        disable: æ˜¯å¦ç¦ç”¨
        
    Example:
        for item in show_progress(items, desc="Processing"):
            process(item)
    """
    try:
        from tqdm import tqdm
        return tqdm(iterable, desc=desc, total=total, unit=unit, disable=disable)
    except ImportError:
        # å¦‚æœæ²¡æœ‰ tqdmï¼Œè¿”å›åŸå§‹è¿­ä»£å™¨
        return iterable


# ============================================
# 7. æ–‡ä»¶æ“ä½œå·¥å…·
# ============================================

def safe_filename(filename: str, max_length: int = 255) -> str:
    """
    ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
    
    Args:
        filename: åŸå§‹æ–‡ä»¶å
        max_length: æœ€å¤§é•¿åº¦
        
    Returns:
        å®‰å…¨çš„æ–‡ä»¶å
    """
    # ç§»é™¤ä¸å®‰å…¨å­—ç¬¦
    import re
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    
    # é™åˆ¶é•¿åº¦
    if len(filename) > max_length:
        name, ext = Path(filename).stem, Path(filename).suffix
        max_name_length = max_length - len(ext)
        filename = name[:max_name_length] + ext
        
    return filename


def get_file_hash(filepath: Path) -> str:
    """
    è®¡ç®—æ–‡ä»¶ MD5 å“ˆå¸Œ
    
    Args:
        filepath: æ–‡ä»¶è·¯å¾„
        
    Returns:
        MD5 å“ˆå¸Œå€¼
    """
    md5 = hashlib.md5()
    
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            md5.update(chunk)
            
    return md5.hexdigest()


def format_bytes(size: int) -> str:
    """
    æ ¼å¼åŒ–å­—èŠ‚å¤§å°
    
    Args:
        size: å­—èŠ‚æ•°
        
    Returns:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼ˆå¦‚ "1.5 MB"ï¼‰
    """
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size < 1024.0:
            return f"{size:.2f} {unit}"
        size /= 1024.0
    return f"{size:.2f} PB"


# ============================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================

if __name__ == "__main__":
    # 1. æ—¥å¿—ç³»ç»Ÿ
    logger = setup_logger("TestApp", "INFO", "logs/test.log")
    logger.info("âœ… æ—¥å¿—ç³»ç»Ÿæµ‹è¯•")
    logger.warning("âš ï¸  è­¦å‘Šæµ‹è¯•")
    logger.error("âŒ é”™è¯¯æµ‹è¯•")
    
    # 2. æ€§èƒ½ç›‘æ§
    metrics = PerformanceMetrics()
    
    with metrics.timer('task1'):
        time.sleep(0.1)
        
    with metrics.timer('task2'):
        time.sleep(0.2)
        
    metrics.increment('processed', 100)
    metrics.print_stats()
    
    # 3. ç¼“å­˜ç³»ç»Ÿ
    cache = DiskCache("data/test_cache")
    cache.set("test_key", {"data": "value"})
    result = cache.get("test_key")
    print(f"ç¼“å­˜ç»“æœ: {result}")
    cache.stats()
    cache.clear()
    
    # 4. é‡è¯•æœºåˆ¶
    @retry_on_failure(max_retries=3, delay=0.5, logger=logger)
    def unstable_function():
        import random
        if random.random() < 0.7:
            raise Exception("éšæœºå¤±è´¥")
        return "æˆåŠŸ"
    
    try:
        result = unstable_function()
        print(f"é‡è¯•ç»“æœ: {result}")
    except Exception as e:
        print(f"æœ€ç»ˆå¤±è´¥: {e}")
    
    # 5. æ‰¹å¤„ç†
    items = list(range(100))
    for i, batch in enumerate(batch_iterator(items, 32)):
        print(f"æ‰¹æ¬¡ {i+1}: {len(batch)} é¡¹")
    
    # 6. æ–‡ä»¶å·¥å…·
    print(f"å®‰å…¨æ–‡ä»¶å: {safe_filename('test<file>name?.txt')}")
    print(f"æ ¼å¼åŒ–å¤§å°: {format_bytes(1536000)}")
    
    print("\nâœ… æ‰€æœ‰å·¥å…·æµ‹è¯•å®Œæˆï¼")
